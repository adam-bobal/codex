{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a8f44fd",
   "metadata": {},
   "source": [
    "# Market Research Data Sources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450a4191",
   "metadata": {},
   "source": [
    "## Industry Reports & Analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ceb4f9ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lubuntu/myenv/lib/python3.12/site-packages/pytrends/request.py:260: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.fillna(False)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 21\u001b[39m\n\u001b[32m     17\u001b[39m     related_queries = pytrends.related_queries()\n\u001b[32m     19\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m trends_data, related_queries\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m trends, queries = \u001b[43manalyze_woodworking_trends\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 17\u001b[39m, in \u001b[36manalyze_woodworking_trends\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     14\u001b[39m trends_data = pytrends.interest_over_time()\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# Get related queries\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m related_queries = \u001b[43mpytrends\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrelated_queries\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m trends_data, related_queries\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/myenv/lib/python3.12/site-packages/pytrends/request.py:450\u001b[39m, in \u001b[36mTrendReq.related_queries\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    447\u001b[39m \u001b[38;5;66;03m# top queries\u001b[39;00m\n\u001b[32m    448\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    449\u001b[39m     top_df = pd.DataFrame(\n\u001b[32m--> \u001b[39m\u001b[32m450\u001b[39m         \u001b[43mreq_json\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdefault\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mrankedList\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[33m'\u001b[39m\u001b[33mrankedKeyword\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m    451\u001b[39m     top_df = top_df[[\u001b[33m'\u001b[39m\u001b[33mquery\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mvalue\u001b[39m\u001b[33m'\u001b[39m]]\n\u001b[32m    452\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[32m    453\u001b[39m     \u001b[38;5;66;03m# in case no top queries are found, the lines above will throw a KeyError\u001b[39;00m\n",
      "\u001b[31mIndexError\u001b[39m: list index out of range"
     ]
    }
   ],
   "source": [
    "# Google Trends for woodworking demand\n",
    "from pytrends.request import TrendReq\n",
    "\n",
    "def analyze_woodworking_trends():\n",
    "    pytrends = TrendReq(hl='en-US', tz=360)\n",
    "    \n",
    "    # Woodworking-related keywords\n",
    "    keywords = ['custom furniture', 'woodworking', 'handmade furniture', \n",
    "               'live edge table', 'custom cabinets']\n",
    "    \n",
    "    pytrends.build_payload(keywords, timeframe='today 12-m', geo='US')\n",
    "    \n",
    "    # Get interest over time\n",
    "    trends_data = pytrends.interest_over_time()\n",
    "    \n",
    "    # Get related queries\n",
    "    related_queries = pytrends.related_queries()\n",
    "    \n",
    "    return trends_data, related_queries\n",
    "\n",
    "trends, queries = analyze_woodworking_trends()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3c1fe2",
   "metadata": {},
   "source": [
    "### Anthropic Attempted Fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e88f97d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting woodworking trends analysis...\n",
      "Building payload...\n",
      "Error: Retry.__init__() got an unexpected keyword argument 'method_whitelist'\n",
      "Trying alternative approach...\n",
      "Analyzing: woodworking\n",
      "Failed for woodworking: Retry.__init__() got an unexpected keyword argument 'method_whitelist'\n",
      "Analyzing: custom furniture\n",
      "Failed for custom furniture: Retry.__init__() got an unexpected keyword argument 'method_whitelist'\n",
      "Analyzing: handmade furniture\n",
      "Failed for handmade furniture: Retry.__init__() got an unexpected keyword argument 'method_whitelist'\n",
      "No data retrieved. Google Trends might be blocking requests.\n",
      "Try again later or use a different approach.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import random\n",
    "from pytrends.request import TrendReq\n",
    "import pandas as pd\n",
    "\n",
    "def analyze_woodworking_trends():\n",
    "    try:\n",
    "        # Initialize with different settings\n",
    "        pytrends = TrendReq(hl='en-US', tz=360, timeout=(10,25), retries=2, backoff_factor=0.1)\n",
    "        \n",
    "        # Use fewer keywords (max 5 per request)\n",
    "        keywords = ['custom furniture', 'woodworking', 'handmade furniture']\n",
    "        \n",
    "        # Add random delay to avoid rate limiting\n",
    "        time.sleep(random.uniform(1, 3))\n",
    "        \n",
    "        print(\"Building payload...\")\n",
    "        pytrends.build_payload(keywords, timeframe='today 12-m', geo='US')\n",
    "        \n",
    "        print(\"Getting interest over time...\")\n",
    "        trends_data = pytrends.interest_over_time()\n",
    "        \n",
    "        # Add delay before next request\n",
    "        time.sleep(random.uniform(2, 4))\n",
    "        \n",
    "        print(\"Getting related queries...\")\n",
    "        related_queries = pytrends.related_queries()\n",
    "        \n",
    "        return trends_data, related_queries\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        print(\"Trying alternative approach...\")\n",
    "        return analyze_with_smaller_batches()\n",
    "\n",
    "def analyze_with_smaller_batches():\n",
    "    \"\"\"Alternative approach with individual keyword analysis\"\"\"\n",
    "    pytrends = TrendReq(hl='en-US', tz=360, timeout=(10,25), retries=2, backoff_factor=0.1)\n",
    "    \n",
    "    keywords = ['woodworking', 'custom furniture', 'handmade furniture']\n",
    "    all_data = {}\n",
    "    \n",
    "    for keyword in keywords:\n",
    "        try:\n",
    "            print(f\"Analyzing: {keyword}\")\n",
    "            time.sleep(random.uniform(2, 4))  # Longer delay between requests\n",
    "            \n",
    "            pytrends.build_payload([keyword], timeframe='today 12-m', geo='US')\n",
    "            trends = pytrends.interest_over_time()\n",
    "            \n",
    "            if not trends.empty:\n",
    "                all_data[keyword] = trends[keyword]\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Failed for {keyword}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    if all_data:\n",
    "        combined_df = pd.DataFrame(all_data)\n",
    "        return combined_df, None\n",
    "    else:\n",
    "        return None, None\n",
    "\n",
    "# Run the analysis\n",
    "print(\"Starting woodworking trends analysis...\")\n",
    "trends, queries = analyze_woodworking_trends()\n",
    "\n",
    "if trends is not None and not trends.empty:\n",
    "    print(\"\\n=== TRENDS DATA ===\")\n",
    "    print(trends.head())\n",
    "    print(f\"\\nShape: {trends.shape}\")\n",
    "    \n",
    "    if queries:\n",
    "        print(\"\\n=== RELATED QUERIES ===\")\n",
    "        for keyword, query_data in queries.items():\n",
    "            print(f\"\\n{keyword.upper()}:\")\n",
    "            if query_data['top'] is not None:\n",
    "                print(\"Top queries:\")\n",
    "                print(query_data['top'].head())\n",
    "else:\n",
    "    print(\"No data retrieved. Google Trends might be blocking requests.\")\n",
    "    print(\"Try again later or use a different approach.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704b355b",
   "metadata": {},
   "source": [
    "### Google Fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64c391f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching interest over time for all keywords...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lubuntu/myenv/lib/python3.12/site-packages/pytrends/request.py:260: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.fillna(False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fetching related queries for each keyword...\n",
      "Fetching for: 'custom furniture'\n",
      "Could not fetch related queries for 'custom furniture'. Error: list index out of range\n",
      "Fetching for: 'woodworking'\n",
      "Could not fetch related queries for 'woodworking'. Error: list index out of range\n",
      "Fetching for: 'handmade furniture'\n",
      "Could not fetch related queries for 'handmade furniture'. Error: list index out of range\n",
      "Fetching for: 'live edge table'\n",
      "Could not fetch related queries for 'live edge table'. Error: list index out of range\n",
      "Fetching for: 'custom cabinets'\n",
      "Could not fetch related queries for 'custom cabinets'. Error: list index out of range\n",
      "\n",
      "--- Interest Over Time ---\n",
      "            custom furniture  woodworking  handmade furniture  \\\n",
      "date                                                            \n",
      "2025-06-01                10           70                   1   \n",
      "2025-06-08                12           68                   1   \n",
      "2025-06-15                10           71                   1   \n",
      "2025-06-22                10           73                   1   \n",
      "2025-06-29                11           66                   1   \n",
      "\n",
      "            live edge table  custom cabinets  isPartial  \n",
      "date                                                     \n",
      "2025-06-01                5               15      False  \n",
      "2025-06-08                4               15      False  \n",
      "2025-06-15                5               15      False  \n",
      "2025-06-22                5               15      False  \n",
      "2025-06-29                5               13       True  \n",
      "\n",
      "\n",
      "--- Related Queries ---\n"
     ]
    }
   ],
   "source": [
    "# Google Trends for woodworking demand\n",
    "import pandas as pd\n",
    "from pytrends.request import TrendReq\n",
    "import time # Import the time module to pause between requests\n",
    "\n",
    "def analyze_woodworking_trends():\n",
    "    \"\"\"\n",
    "    Analyzes Google Trends for woodworking keywords.\n",
    "\n",
    "    Fetches interest over time for a list of keywords and then fetches\n",
    "    related queries for each keyword individually.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing interest over time data.\n",
    "        dict: A dictionary containing related queries for each keyword.\n",
    "    \"\"\"\n",
    "    pytrends = TrendReq(hl='en-US', tz=360)\n",
    "    \n",
    "    # Woodworking-related keywords\n",
    "    keywords = ['custom furniture', 'woodworking', 'handmade furniture', \n",
    "               'live edge table', 'custom cabinets']\n",
    "    \n",
    "    # --- 1. Get Interest Over Time for all keywords (for comparison) ---\n",
    "    print(\"Fetching interest over time for all keywords...\")\n",
    "    pytrends.build_payload(keywords, timeframe='today 12-m', geo='US')\n",
    "    trends_data = pytrends.interest_over_time()\n",
    "    \n",
    "    # --- 2. Get Related Queries for each keyword individually ---\n",
    "    related_queries_dict = {}\n",
    "    print(\"\\nFetching related queries for each keyword...\")\n",
    "    \n",
    "    for keyword in keywords:\n",
    "        print(f\"Fetching for: '{keyword}'\")\n",
    "        # Build a new payload for each individual keyword\n",
    "        pytrends.build_payload([keyword], timeframe='today 12-m', geo='US')\n",
    "        \n",
    "        # Add a small delay to avoid making requests too quickly\n",
    "        time.sleep(1) \n",
    "        \n",
    "        try:\n",
    "            related_queries_dict[keyword] = pytrends.related_queries()\n",
    "        except Exception as e:\n",
    "            print(f\"Could not fetch related queries for '{keyword}'. Error: {e}\")\n",
    "            related_queries_dict[keyword] = None\n",
    "\n",
    "    return trends_data, related_queries_dict\n",
    "\n",
    "# Run the analysis\n",
    "trends_df, related_queries = analyze_woodworking_trends()\n",
    "\n",
    "# --- Display the results ---\n",
    "print(\"\\n--- Interest Over Time ---\")\n",
    "print(trends_df.tail()) # Print the last 5 rows of the trend data\n",
    "\n",
    "print(\"\\n\\n--- Related Queries ---\")\n",
    "for keyword, queries in related_queries.items():\n",
    "    if queries:\n",
    "        print(f\"\\nTop Related Queries for '{keyword}':\")\n",
    "        # The result is a dictionary where the value is another dictionary with 'top' and 'rising'\n",
    "        top_queries = queries[keyword]['top']\n",
    "        if top_queries is not None and not top_queries.empty:\n",
    "            print(top_queries)\n",
    "        else:\n",
    "            print(\"No top related queries found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4171eb9",
   "metadata": {},
   "source": [
    "#### Google Response to Broken API Endpoint\n",
    "\n",
    "     ```\n",
    "\n",
    "# Google Trends for woodworking demand\n",
    "\n",
    "from pytrends.request import TrendReq\n",
    "\n",
    "\n",
    "def analyze_woodworking_trends():\n",
    "\n",
    "pytrends = TrendReq(hl='en-US', tz=360)\n",
    "\n",
    "# Woodworking-related keywords\n",
    "\n",
    "keywords = ['custom furniture', 'woodworking', 'handmade furniture',\n",
    "\n",
    "'live edge table', 'custom cabinets']\n",
    "\n",
    "pytrends.build_payload(keywords, timeframe='today 12-m', geo='US')\n",
    "\n",
    "# Get interest over time\n",
    "\n",
    "trends_data = pytrends.interest_over_time()\n",
    "\n",
    "# Get related queries\n",
    "\n",
    "related_queries = pytrends.related_queries()\n",
    "\n",
    "return trends_data, related_queries\n",
    "\n",
    "\n",
    "trends, queries = analyze_woodworking_trends()\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "/home/lubuntu/myenv/lib/python3.12/site-packages/pytrends/request.py:260: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
    "\n",
    "df = df.fillna(False)\n",
    "\n",
    "\n",
    "---------------------------------------------------------------------------\n",
    "\n",
    "IndexError Traceback (most recent call last)\n",
    "\n",
    "Cell In[4], line 21\n",
    "\n",
    "17 related_queries = pytrends.related_queries()\n",
    "\n",
    "19 return trends_data, related_queries\n",
    "\n",
    "---> 21 trends, queries = analyze_woodworking_trends()\n",
    "\n",
    "Cell In[4], line 17, in analyze_woodworking_trends()\n",
    "\n",
    "14 trends_data = pytrends.interest_over_time()\n",
    "\n",
    "16 # Get related queries\n",
    "\n",
    "---> 17 related_queries = pytrends.related_queries()\n",
    "\n",
    "19 return trends_data, related_queries\n",
    "\n",
    "File ~/myenv/lib/python3.12/site-packages/pytrends/request.py:450, in TrendReq.related_queries(self)\n",
    "\n",
    "447 # top queries\n",
    "\n",
    "448 try:\n",
    "\n",
    "449 top_df = pd.DataFrame(\n",
    "\n",
    "--> 450 req_json['default']['rankedList'][0]['rankedKeyword'])\n",
    "\n",
    "451 top_df = top_df[['query', 'value']]\n",
    "\n",
    "452 except KeyError:\n",
    "\n",
    "453 # in case no top queries are found, the lines above will throw a KeyError\n",
    "\n",
    "IndexError: list index out of range\n",
    "\n",
    "Outline\n",
    "\n",
    "    Diagnosis of the IndexError: An explanation of why the IndexError: list index out of range occurs when using related_queries() with multiple keywords.\n",
    "\n",
    "    The Solution: A description of the correct approach, which involves iterating through each keyword to fetch its related queries individually.\n",
    "\n",
    "    Corrected Python Code: A complete, runnable code snippet that implements the solution and correctly fetches both interest over time for all keywords and related queries for each keyword.\n",
    "\n",
    "    Explanation of Changes: A step-by-step breakdown of the modifications made to the original code.\n",
    "\n",
    "    A Note on the FutureWarning: A brief explanation of the warning message appearing in the output.\n",
    "\n",
    "1. Diagnosis of the IndexError\n",
    "\n",
    "Hello! I can help you with this Python error. The IndexError: list index out of range you're encountering is a common issue when using the pytrends library.\n",
    "\n",
    "The root cause of the problem is that the pytrends.related_queries() method is designed to fetch data for only one keyword at a time.\n",
    "\n",
    "In your original code, you build a single payload with a list of five keywords:\n",
    "pytrends.build_payload(keywords, ...)\n",
    "\n",
    "While interest_over_time() can handle multiple keywords to generate a comparison chart, related_queries() cannot. When it receives a payload with more than one keyword, the Google Trends API returns a data structure that pytrends doesn't expect. Specifically, the list that should contain the related query data (rankedList) comes back empty. The library then tries to access the first element of this empty list ([0]), which triggers the IndexError.\n",
    "\n",
    "2. The Solution\n",
    "\n",
    "To fix this, you need to separate the logic for fetching \"interest over time\" and \"related queries.\"\n",
    "\n",
    "    Interest Over Time: You can continue to fetch this data in a single call with all your keywords to get a comparison.\n",
    "\n",
    "    Related Queries: You must loop through your list of keywords and make a separate API call for each one. You can store the results in a dictionary where the keys are your keywords and the values are the corresponding related queries.\n",
    "\n",
    "3. Corrected Python Code\n",
    "\n",
    "Here is the corrected and complete code. This version first gets the comparison data for all keywords and then iterates through each keyword to safely get its related queries.\n",
    "Python\n",
    "\n",
    "# Google Trends for woodworking demand\n",
    "import pandas as pd\n",
    "from pytrends.request import TrendReq\n",
    "import time # Import the time module to pause between requests\n",
    "\n",
    "def analyze_woodworking_trends():\n",
    "    \"\"\"\n",
    "    Analyzes Google Trends for woodworking keywords.\n",
    "\n",
    "    Fetches interest over time for a list of keywords and then fetches\n",
    "    related queries for each keyword individually.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing interest over time data.\n",
    "        dict: A dictionary containing related queries for each keyword.\n",
    "    \"\"\"\n",
    "    pytrends = TrendReq(hl='en-US', tz=360)\n",
    "    \n",
    "    # Woodworking-related keywords\n",
    "    keywords = ['custom furniture', 'woodworking', 'handmade furniture', \n",
    "               'live edge table', 'custom cabinets']\n",
    "    \n",
    "    # --- 1. Get Interest Over Time for all keywords (for comparison) ---\n",
    "    print(\"Fetching interest over time for all keywords...\")\n",
    "    pytrends.build_payload(keywords, timeframe='today 12-m', geo='US')\n",
    "    trends_data = pytrends.interest_over_time()\n",
    "    \n",
    "    # --- 2. Get Related Queries for each keyword individually ---\n",
    "    related_queries_dict = {}\n",
    "    print(\"\\nFetching related queries for each keyword...\")\n",
    "    \n",
    "    for keyword in keywords:\n",
    "        print(f\"Fetching for: '{keyword}'\")\n",
    "        # Build a new payload for each individual keyword\n",
    "        pytrends.build_payload([keyword], timeframe='today 12-m', geo='US')\n",
    "        \n",
    "        # Add a small delay to avoid making requests too quickly\n",
    "        time.sleep(1) \n",
    "        \n",
    "        try:\n",
    "            related_queries_dict[keyword] = pytrends.related_queries()\n",
    "        except Exception as e:\n",
    "            print(f\"Could not fetch related queries for '{keyword}'. Error: {e}\")\n",
    "            related_queries_dict[keyword] = None\n",
    "\n",
    "    return trends_data, related_queries_dict\n",
    "\n",
    "# Run the analysis\n",
    "trends_df, related_queries = analyze_woodworking_trends()\n",
    "\n",
    "# --- Display the results ---\n",
    "print(\"\\n--- Interest Over Time ---\")\n",
    "print(trends_df.tail()) # Print the last 5 rows of the trend data\n",
    "\n",
    "print(\"\\n\\n--- Related Queries ---\")\n",
    "for keyword, queries in related_queries.items():\n",
    "    if queries:\n",
    "        print(f\"\\nTop Related Queries for '{keyword}':\")\n",
    "        # The result is a dictionary where the value is another dictionary with 'top' and 'rising'\n",
    "        top_queries = queries[keyword]['top']\n",
    "        if top_queries is not None and not top_queries.empty:\n",
    "            print(top_queries)\n",
    "        else:\n",
    "            print(\"No top related queries found.\")\n",
    "\n",
    "4. Explanation of Changes\n",
    "\n",
    "    Separate API Calls: The core logic is now split. The call to get interest_over_time remains as it was, using the full list of keywords.\n",
    "\n",
    "    Loop for Related Queries: A for loop iterates through your keywords list.\n",
    "\n",
    "    Single-Keyword Payload: Inside the loop, pytrends.build_payload([keyword], ...) is called. Note that keyword is enclosed in square brackets [] because the method expects a list, even if it's just a list containing one item.\n",
    "\n",
    "    Storing Results: The results from pytrends.related_queries() are stored in a dictionary called related_queries_dict. This is a clean way to associate each keyword with its specific results.\n",
    "\n",
    "    Error Handling & Delay:\n",
    "\n",
    "        time.sleep(1): A one-second pause is added in the loop. It's good practice to add a small delay between API calls to avoid being rate-limited or blocked by Google for making too many requests too quickly.\n",
    "\n",
    "        try...except: I've wrapped the related_queries() call in a try...except block. This makes the code more robust. If Google Trends has no related query data for a specific term, it might still cause an error, and this block will catch it, print a message, and allow the script to continue to the next keyword instead of crashing.\n",
    "\n",
    "5. A Note on the FutureWarning\n",
    "\n",
    "You may still see this warning in your output:\n",
    "FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated...\n",
    "\n",
    "This warning is not causing your IndexError. It originates from the pandas library, which pytrends uses internally. It's simply informing you that a function pandas uses will behave differently in a future version. This is a message for the developers of pytrends to address in a future update. You can safely ignore this warning as it does not affect the execution or results of your code.\n",
    "\n",
    "\n",
    "Fetching related queries for each keyword...\n",
    "\n",
    "Fetching for: 'custom furniture'\n",
    "\n",
    "Could not fetch related queries for 'custom furniture'. Error: list index out of range\n",
    "\n",
    "Fetching for: 'woodworking'\n",
    "\n",
    "Could not fetch related queries for 'woodworking'. Error: list index out of range\n",
    "\n",
    "Fetching for: 'handmade furniture'\n",
    "\n",
    "Could not fetch related queries for 'handmade furniture'. Error: list index out of range\n",
    "\n",
    "Fetching for: 'live edge table'\n",
    "\n",
    "Could not fetch related queries for 'live edge table'. Error: list index out of range\n",
    "\n",
    "Fetching for: 'custom cabinets'\n",
    "\n",
    "Could not fetch related queries for 'custom cabinets'. Error: list index out of range\n",
    "\n",
    "\n",
    "--- Interest Over Time ---\n",
    "\n",
    "custom furniture woodworking handmade furniture \\\n",
    "\n",
    "date\n",
    "\n",
    "2025-06-01 10 70 1\n",
    "\n",
    "2025-06-08 12 68 1\n",
    "\n",
    "2025-06-15 10 71 1\n",
    "\n",
    "2025-06-22 10 73 1\n",
    "\n",
    "2025-06-29 11 66 1\n",
    "\n",
    "\n",
    "live edge table custom cabinets isPartial\n",
    "\n",
    "date\n",
    "\n",
    "2025-06-01 5 15 False\n",
    "\n",
    "2025-06-08 4 15 False\n",
    "\n",
    "2025-06-15 5 15 False\n",
    "\n",
    "2025-06-22 5 15 False\n",
    "\n",
    "2025-06-29 5 13 True\n",
    "\n",
    "\n",
    "\n",
    "--- Related Queries ---\n",
    "\n",
    "\n",
    "You've run into a frustrating and unfortunately common issue with the pytrends library. Your new output confirms that the error isn't just about sending multiple keywords at once, but is a more fundamental problem with the related_queries() function itself.\n",
    "\n",
    "Let's break down what's happening and how to build a more robust script to handle it.\n",
    "\n",
    "Outline\n",
    "\n",
    "    Diagnosis of the Persistent Error: An explanation of why the IndexError continues to happen even with single keywords, pointing to an issue within the pytrends library itself.\n",
    "\n",
    "    The Fragility of Unofficial Wrappers: A brief look at why libraries like pytrends can sometimes break.\n",
    "\n",
    "    Robust Solution: A revised code block that anticipates these errors and safely handles the data that is returned, preventing crashes and extracting whatever information is available.\n",
    "\n",
    "    Interpreting the New Results: How to understand the output from the robust script.\n",
    "\n",
    "1. Diagnosis of the Persistent Error\n",
    "\n",
    "The fact that you are now getting the IndexError: list index out of range for every single keyword tells us the problem lies within the pytrends library's ability to parse the response it's getting from Google.\n",
    "\n",
    "Here's the situation:\n",
    "\n",
    "    You send a valid request for a single keyword (e.g., 'woodworking').\n",
    "\n",
    "    Google Trends sends back a response.\n",
    "\n",
    "    The structure of this response has likely changed slightly from what the pytrends library was originally designed to expect.\n",
    "\n",
    "    When the related_queries() method tries to find the data in the specific location it's hard-coded to look (req_json['default']['rankedList'][0]), it finds an empty list ([]) and crashes when it tries to get the first item ([0]).\n",
    "\n",
    "This happens even when there are related queries visible on the Google Trends website. The issue is purely in the parsing step within the library.\n",
    "\n",
    "2. The Fragility of Unofficial Wrappers\n",
    "\n",
    "pytrends is an unofficial \"wrapper\" library. It works by mimicking a web browser to scrape the Google Trends website and access its internal API. This is a brilliant but fragile approach. If Google changes the backend structure of their website or API—even slightly—the library can break until its developers release a new version that accounts for the change. You appear to have caught it during one of these broken periods.\n",
    "\n",
    "3. Robust Solution\n",
    "\n",
    "We cannot fix the pytrends library itself, but we can write our Python code to be more defensive. The goal is to successfully call the function and then carefully inspect whatever data we get back, rather than assuming it's in the correct format.\n",
    "\n",
    "The code below is designed to handle this IndexError gracefully. It attempts the call and then safely checks the structure of the returned dictionary before trying to extract the 'top' and 'rising' queries.\n",
    "Python\n",
    "\n",
    "# Google Trends for woodworking demand\n",
    "import pandas as pd\n",
    "from pytrends.request import TrendReq\n",
    "import time\n",
    "\n",
    "def analyze_woodworking_trends():\n",
    "    \"\"\"\n",
    "    Analyzes Google Trends for woodworking keywords.\n",
    "\n",
    "    This robust version anticipates potential errors from the pytrends library\n",
    "    and handles them gracefully.\n",
    "    \"\"\"\n",
    "    pytrends = TrendReq(hl='en-US', tz=360)\n",
    "    \n",
    "    keywords = ['custom furniture', 'woodworking', 'handmade furniture', \n",
    "               'live edge table', 'custom cabinets']\n",
    "    \n",
    "    # --- 1. Get Interest Over Time (this part usually works reliably) ---\n",
    "    print(\"Fetching interest over time for all keywords...\")\n",
    "    try:\n",
    "        pytrends.build_payload(keywords, timeframe='today 12-m', geo='US')\n",
    "        trends_data = pytrends.interest_over_time()\n",
    "    except Exception as e:\n",
    "        print(f\"Could not fetch interest over time. Error: {e}\")\n",
    "        trends_data = None\n",
    "    \n",
    "    # --- 2. Get Related Queries with Robust Error Handling ---\n",
    "    related_queries_dict = {}\n",
    "    print(\"\\nFetching related queries for each keyword...\")\n",
    "    \n",
    "    for keyword in keywords:\n",
    "        print(f\"Fetching for: '{keyword}'\")\n",
    "        time.sleep(2) # Increased delay to be safe\n",
    "        \n",
    "        try:\n",
    "            # Re-build payload for each keyword\n",
    "            pytrends.build_payload([keyword], timeframe='today 12-m', geo='US')\n",
    "            related_queries_dict[keyword] = pytrends.related_queries()\n",
    "        except IndexError:\n",
    "            # This is the specific error we are seeing.\n",
    "            print(f\"  > Caught IndexError. Google's API response is not in the expected format for '{keyword}'.\")\n",
    "            related_queries_dict[keyword] = None # Mark as failed\n",
    "        except Exception as e:\n",
    "            # Catch any other potential errors\n",
    "            print(f\"  > An unexpected error occurred for '{keyword}': {e}\")\n",
    "            related_queries_dict[keyword] = None # Mark as failed\n",
    "            \n",
    "    return trends_data, related_queries_dict\n",
    "\n",
    "# --- Run the analysis and display results safely ---\n",
    "trends_df, related_queries = analyze_woodworking_trends()\n",
    "\n",
    "if trends_df is not None:\n",
    "    print(\"\\n\\n--- Interest Over Time ---\")\n",
    "    print(trends_df.tail())\n",
    "else:\n",
    "    print(\"\\n\\n--- No Interest Over Time data was fetched ---\")\n",
    "\n",
    "print(\"\\n\\n--- Related Queries ---\")\n",
    "if not related_queries:\n",
    "    print(\"No related queries could be fetched.\")\n",
    "else:\n",
    "    for keyword, result in related_queries.items():\n",
    "        print(f\"\\n--- Results for '{keyword}' ---\")\n",
    "        if result is None:\n",
    "            print(\"  > No data returned due to an API parsing error.\")\n",
    "            continue\n",
    "        \n",
    "        # Safely access 'top' and 'rising' queries\n",
    "        top_queries = result.get(keyword, {}).get('top')\n",
    "        rising_queries = result.get(keyword, {}).get('rising')\n",
    "        \n",
    "        if top_queries is not None and not top_queries.empty:\n",
    "            print(\"\\n  Top Related Queries:\")\n",
    "            print(top_queries)\n",
    "        else:\n",
    "            print(\"\\n  > No 'Top' related queries were found or could be parsed.\")\n",
    "            \n",
    "        if rising_queries is not None and not rising_queries.empty:\n",
    "            print(\"\\n  Rising Related Queries:\")\n",
    "            print(rising_queries)\n",
    "        else:\n",
    "            print(\"\\n  > No 'Rising' related queries were found or could be parsed.\")\n",
    "\n",
    "4. Interpreting the New Results\n",
    "\n",
    "When you run this new script, you will likely see a similar output to what you got before, but with more descriptive messages:\n",
    "Plaintext\n",
    "\n",
    "Fetching for: 'custom furniture'\n",
    "  > Caught IndexError. Google's API response is not in the expected format for 'custom furniture'.\n",
    "... (and so on for other keywords)\n",
    "\n",
    "At the end, the results section will clearly state that no data could be parsed.\n",
    "\n",
    "What to do now?\n",
    "\n",
    "    Wait for an Update: The most common solution is to wait for the pytrends developers to patch the library. You can check for updates periodically by running pip install --upgrade pytrends.\n",
    "\n",
    "    Try Different Parameters: You can experiment by changing the timeframe. Sometimes a shorter timeframe like 'today 3-m' or 'now 7-d' might use a different API endpoint that isn't broken.\n",
    "\n",
    "    Use the Website: For the time being, the most reliable way to get related queries is to go directly to the Google Trends website and search for your terms manually.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad5ff0e",
   "metadata": {},
   "source": [
    "## E-commerce Platform APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b983ad3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching interest over time for all keywords...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lubuntu/myenv/lib/python3.12/site-packages/pytrends/request.py:260: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.fillna(False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fetching related queries for each keyword...\n",
      "Fetching for: 'custom furniture'\n",
      "  > Caught IndexError. Google's API response is not in the expected format for 'custom furniture'.\n",
      "Fetching for: 'woodworking'\n",
      "  > Caught IndexError. Google's API response is not in the expected format for 'woodworking'.\n",
      "Fetching for: 'handmade furniture'\n",
      "  > Caught IndexError. Google's API response is not in the expected format for 'handmade furniture'.\n",
      "Fetching for: 'live edge table'\n",
      "  > Caught IndexError. Google's API response is not in the expected format for 'live edge table'.\n",
      "Fetching for: 'custom cabinets'\n",
      "  > Caught IndexError. Google's API response is not in the expected format for 'custom cabinets'.\n",
      "\n",
      "\n",
      "--- Interest Over Time ---\n",
      "            custom furniture  woodworking  handmade furniture  \\\n",
      "date                                                            \n",
      "2025-06-01                10           70                   1   \n",
      "2025-06-08                12           68                   1   \n",
      "2025-06-15                10           71                   1   \n",
      "2025-06-22                10           73                   1   \n",
      "2025-06-29                11           71                   1   \n",
      "\n",
      "            live edge table  custom cabinets  isPartial  \n",
      "date                                                     \n",
      "2025-06-01                5               15      False  \n",
      "2025-06-08                4               15      False  \n",
      "2025-06-15                5               15      False  \n",
      "2025-06-22                5               15      False  \n",
      "2025-06-29                5               13       True  \n",
      "\n",
      "\n",
      "--- Related Queries ---\n",
      "\n",
      "--- Results for 'custom furniture' ---\n",
      "  > No data returned due to an API parsing error.\n",
      "\n",
      "--- Results for 'woodworking' ---\n",
      "  > No data returned due to an API parsing error.\n",
      "\n",
      "--- Results for 'handmade furniture' ---\n",
      "  > No data returned due to an API parsing error.\n",
      "\n",
      "--- Results for 'live edge table' ---\n",
      "  > No data returned due to an API parsing error.\n",
      "\n",
      "--- Results for 'custom cabinets' ---\n",
      "  > No data returned due to an API parsing error.\n"
     ]
    }
   ],
   "source": [
    "# Google Trends for woodworking demand\n",
    "import pandas as pd\n",
    "from pytrends.request import TrendReq\n",
    "import time\n",
    "\n",
    "def analyze_woodworking_trends():\n",
    "    \"\"\"\n",
    "    Analyzes Google Trends for woodworking keywords.\n",
    "\n",
    "    This robust version anticipates potential errors from the pytrends library\n",
    "    and handles them gracefully.\n",
    "    \"\"\"\n",
    "    pytrends = TrendReq(hl='en-US', tz=360)\n",
    "    \n",
    "    keywords = ['custom furniture', 'woodworking', 'handmade furniture', \n",
    "               'live edge table', 'custom cabinets']\n",
    "    \n",
    "    # --- 1. Get Interest Over Time (this part usually works reliably) ---\n",
    "    print(\"Fetching interest over time for all keywords...\")\n",
    "    try:\n",
    "        pytrends.build_payload(keywords, timeframe='today 12-m', geo='US')\n",
    "        trends_data = pytrends.interest_over_time()\n",
    "    except Exception as e:\n",
    "        print(f\"Could not fetch interest over time. Error: {e}\")\n",
    "        trends_data = None\n",
    "    \n",
    "    # --- 2. Get Related Queries with Robust Error Handling ---\n",
    "    related_queries_dict = {}\n",
    "    print(\"\\nFetching related queries for each keyword...\")\n",
    "    \n",
    "    for keyword in keywords:\n",
    "        print(f\"Fetching for: '{keyword}'\")\n",
    "        time.sleep(2) # Increased delay to be safe\n",
    "        \n",
    "        try:\n",
    "            # Re-build payload for each keyword\n",
    "            pytrends.build_payload([keyword], timeframe='today 12-m', geo='US')\n",
    "            related_queries_dict[keyword] = pytrends.related_queries()\n",
    "        except IndexError:\n",
    "            # This is the specific error we are seeing.\n",
    "            print(f\"  > Caught IndexError. Google's API response is not in the expected format for '{keyword}'.\")\n",
    "            related_queries_dict[keyword] = None # Mark as failed\n",
    "        except Exception as e:\n",
    "            # Catch any other potential errors\n",
    "            print(f\"  > An unexpected error occurred for '{keyword}': {e}\")\n",
    "            related_queries_dict[keyword] = None # Mark as failed\n",
    "            \n",
    "    return trends_data, related_queries_dict\n",
    "\n",
    "# --- Run the analysis and display results safely ---\n",
    "trends_df, related_queries = analyze_woodworking_trends()\n",
    "\n",
    "if trends_df is not None:\n",
    "    print(\"\\n\\n--- Interest Over Time ---\")\n",
    "    print(trends_df.tail())\n",
    "else:\n",
    "    print(\"\\n\\n--- No Interest Over Time data was fetched ---\")\n",
    "\n",
    "print(\"\\n\\n--- Related Queries ---\")\n",
    "if not related_queries:\n",
    "    print(\"No related queries could be fetched.\")\n",
    "else:\n",
    "    for keyword, result in related_queries.items():\n",
    "        print(f\"\\n--- Results for '{keyword}' ---\")\n",
    "        if result is None:\n",
    "            print(\"  > No data returned due to an API parsing error.\")\n",
    "            continue\n",
    "        \n",
    "        # Safely access 'top' and 'rising' queries\n",
    "        top_queries = result.get(keyword, {}).get('top')\n",
    "        rising_queries = result.get(keyword, {}).get('rising')\n",
    "        \n",
    "        if top_queries is not None and not top_queries.empty:\n",
    "            print(\"\\n  Top Related Queries:\")\n",
    "            print(top_queries)\n",
    "        else:\n",
    "            print(\"\\n  > No 'Top' related queries were found or could be parsed.\")\n",
    "            \n",
    "        if rising_queries is not None and not rising_queries.empty:\n",
    "            print(\"\\n  Rising Related Queries:\")\n",
    "            print(rising_queries)\n",
    "        else:\n",
    "            print(\"\\n  > No 'Rising' related queries were found or could be parsed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0c63da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Etsy API for handmade/custom furniture market\n",
    "import requests\n",
    "\n",
    "def analyze_etsy_woodworking_market(api_key):\n",
    "    \"\"\"Analyze woodworking market on Etsy\"\"\"\n",
    "    \n",
    "    # Search for woodworking items\n",
    "    url = \"https://openapi.etsy.com/v3/application/listings/active\"\n",
    "    \n",
    "    headers = {\n",
    "        'x-api-key': api_key,\n",
    "        'Content-Type': 'application/json'\n",
    "    }\n",
    "    \n",
    "    params = {\n",
    "        'keywords': 'custom furniture woodworking',\n",
    "        'limit': 100,\n",
    "        'includes': 'Images,Shop,User',\n",
    "        'sort_on': 'score'\n",
    "    }\n",
    "    \n",
    "    response = requests.get(url, headers=headers, params=params)\n",
    "    listings = response.json()\n",
    "    \n",
    "    # Analyze pricing and demand indicators\n",
    "    market_data = []\n",
    "    for listing in listings.get('results', []):\n",
    "        market_data.append({\n",
    "            'title': listing.get('title'),\n",
    "            'price': listing.get('price', {}).get('amount'),\n",
    "            'currency': listing.get('price', {}).get('currency_code'),\n",
    "            'views': listing.get('views'),\n",
    "            'num_favorers': listing.get('num_favorers'),\n",
    "            'shop_name': listing.get('Shop', {}).get('shop_name'),\n",
    "            'creation_timestamp': listing.get('creation_timestamp')\n",
    "        })\n",
    "    \n",
    "    return market_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae3e7d4",
   "metadata": {},
   "source": [
    "## Local Business Intelligence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66307804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google My Business API for local competition analysis\n",
    "def analyze_local_woodworking_businesses(location, gmb_api_key):\n",
    "    \"\"\"Find local woodworking businesses and their performance\"\"\"\n",
    "    import googlemaps\n",
    "    \n",
    "    gmaps = googlemaps.Client(key=gmb_api_key)\n",
    "    \n",
    "    # Search for woodworking businesses\n",
    "    search_terms = [\n",
    "        'custom furniture',\n",
    "        'woodworking shop',\n",
    "        'cabinet maker',\n",
    "        'furniture maker'\n",
    "    ]\n",
    "    \n",
    "    local_businesses = []\n",
    "    \n",
    "    for term in search_terms:\n",
    "        places = gmaps.places_nearby(\n",
    "            location=location,\n",
    "            radius=50000,  # 50km radius\n",
    "            keyword=term,\n",
    "            type='establishment'\n",
    "        )\n",
    "        \n",
    "        for place in places.get('results', []):\n",
    "            place_details = gmaps.place(\n",
    "                place_id=place['place_id'],\n",
    "                fields=['name', 'rating', 'user_ratings_total', 'website', \n",
    "                       'formatted_phone_number', 'opening_hours', 'photos']\n",
    "            )\n",
    "            \n",
    "            local_businesses.append({\n",
    "                'name': place_details['result']['name'],\n",
    "                'rating': place_details['result'].get('rating'),\n",
    "                'review_count': place_details['result'].get('user_ratings_total'),\n",
    "                'website': place_details['result'].get('website'),\n",
    "                'search_term': term\n",
    "            })\n",
    "    \n",
    "    return local_businesses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3921a32",
   "metadata": {},
   "source": [
    "## Price Analysis Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b105f8db",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9cf97e8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34manalyze_pricing_data\u001b[39m(market_data):\n\u001b[32m      5\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Analyze pricing patterns in woodworking market\"\"\"\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def analyze_pricing_data(market_data):\n",
    "    \"\"\"Analyze pricing patterns in woodworking market\"\"\"\n",
    "    \n",
    "    df = pd.DataFrame(market_data)\n",
    "    \n",
    "    # Price analysis by category\n",
    "    price_analysis = {\n",
    "        'avg_price': df['price'].mean(),\n",
    "        'median_price': df['price'].median(),\n",
    "        'price_range': {\n",
    "            'low': df['price'].quantile(0.25),\n",
    "            'high': df['price'].quantile(0.75)\n",
    "        },\n",
    "        'popular_price_points': df['price'].value_counts().head(10)\n",
    "    }\n",
    "    \n",
    "    # Demand indicators\n",
    "    demand_analysis = {\n",
    "        'avg_views': df['views'].mean(),\n",
    "        'avg_favorites': df['num_favorers'].mean(),\n",
    "        'high_demand_items': df.nlargest(10, 'views')[['title', 'price', 'views']]\n",
    "    }\n",
    "    \n",
    "    return price_analysis, demand_analysis\n",
    "\n",
    "def create_market_report(price_analysis, demand_analysis):\n",
    "    \"\"\"Generate market analysis report\"\"\"\n",
    "    \n",
    "    report = f\"\"\"\n",
    "    WOODWORKING MARKET ANALYSIS REPORT\n",
    "    ================================\n",
    "    \n",
    "    PRICING INSIGHTS:\n",
    "    - Average Price: ${price_analysis['avg_price']:.2f}\n",
    "    - Median Price: ${price_analysis['median_price']:.2f}\n",
    "    - Price Range (25th-75th percentile): ${price_analysis['price_range']['low']:.2f} - ${price_analysis['price_range']['high']:.2f}\n",
    "    \n",
    "    DEMAND INDICATORS:\n",
    "    - Average Views per Item: {demand_analysis['avg_views']:.0f}\n",
    "    - Average Favorites per Item: {demand_analysis['avg_favorites']:.0f}\n",
    "    \n",
    "    TOP PERFORMING ITEMS:\n",
    "    {demand_analysis['high_demand_items'].to_string()}\n",
    "    \"\"\"\n",
    "    \n",
    "    return report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d364c63",
   "metadata": {},
   "source": [
    "## Web Scraping for Public Business Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d97443",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping Yellow Pages or similar business directories (public data)\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "def scrape_business_directory(location, category=\"furniture\"):\n",
    "    \"\"\"Scrape public business directory data\"\"\"\n",
    "    \n",
    "    # This is for publicly available directory information\n",
    "    base_url = \"https://www.yellowpages.com/search\"\n",
    "    \n",
    "    params = {\n",
    "        'search_terms': f'{category} woodworking',\n",
    "        'geo_location_terms': location\n",
    "    }\n",
    "    \n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'\n",
    "    }\n",
    "    \n",
    "    businesses = []\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(base_url, params=params, headers=headers)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        \n",
    "        # Extract business information (adjust selectors based on site structure)\n",
    "        business_listings = soup.find_all('div', class_='result')\n",
    "        \n",
    "        for listing in business_listings:\n",
    "            name = listing.find('a', class_='business-name')\n",
    "            rating = listing.find('div', class_='rating')\n",
    "            \n",
    "            if name:\n",
    "                businesses.append({\n",
    "                    'name': name.get_text().strip(),\n",
    "                    'rating': rating.get_text().strip() if rating else 'N/A'\n",
    "                })\n",
    "        \n",
    "        time.sleep(2)  # Be respectful with requests\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error scraping directory: {e}\")\n",
    "    \n",
    "    return businesses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad54d18b",
   "metadata": {},
   "source": [
    "## Social Media Market Research"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c1e55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using official APIs for market research\n",
    "def analyze_woodworking_social_trends():\n",
    "    \"\"\"Analyze social media trends for woodworking\"\"\"\n",
    "    \n",
    "    # Instagram Hashtag Analysis (using official API)\n",
    "    woodworking_hashtags = [\n",
    "        '#customfurniture', '#woodworking', '#handmade', \n",
    "        '#liveedge', '#woodwork', '#furniture'\n",
    "    ]\n",
    "    \n",
    "    # YouTube Data API for woodworking content analysis\n",
    "    def get_youtube_woodworking_data(api_key):\n",
    "        from googleapiclient.discovery import build\n",
    "        \n",
    "        youtube = build('youtube', 'v3', developerKey=api_key)\n",
    "        \n",
    "        search_response = youtube.search().list(\n",
    "            q='woodworking business custom furniture',\n",
    "            part='id,snippet',\n",
    "            maxResults=50,\n",
    "            type='video',\n",
    "            order='relevance'\n",
    "        ).execute()\n",
    "        \n",
    "        video_data = []\n",
    "        for item in search_response['items']:\n",
    "            video_data.append({\n",
    "                'title': item['snippet']['title'],\n",
    "                'description': item['snippet']['description'],\n",
    "                'published_at': item['snippet']['publishedAt']\n",
    "            })\n",
    "        \n",
    "        return video_data\n",
    "    \n",
    "    return woodworking_hashtags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f0dce0",
   "metadata": {},
   "source": [
    "## Demand Forecasting Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1db637",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "\n",
    "def create_demand_forecast(historical_data):\n",
    "    \"\"\"Create demand forecast based on collected data\"\"\"\n",
    "    \n",
    "    df = pd.DataFrame(historical_data)\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df['month'] = df['date'].dt.month\n",
    "    df['year'] = df['date'].dt.year\n",
    "    \n",
    "    # Features for demand prediction\n",
    "    features = ['month', 'year', 'avg_price', 'search_volume']\n",
    "    X = df[features]\n",
    "    y = df['demand_indicator']  # Views, sales, etc.\n",
    "    \n",
    "    # Simple linear regression model\n",
    "    model = LinearRegression()\n",
    "    model.fit(X, y)\n",
    "    \n",
    "    # Forecast next 6 months\n",
    "    future_months = []\n",
    "    current_date = pd.Timestamp.now()\n",
    "    \n",
    "    for i in range(1, 7):\n",
    "        future_date = current_date + pd.DateOffset(months=i)\n",
    "        future_months.append({\n",
    "            'month': future_date.month,\n",
    "            'year': future_date.year,\n",
    "            'avg_price': df['avg_price'].mean(),  # Use historical average\n",
    "            'search_volume': df['search_volume'].mean()\n",
    "        })\n",
    "    \n",
    "    future_df = pd.DataFrame(future_months)\n",
    "    forecast = model.predict(future_df[features])\n",
    "    \n",
    "    return forecast, future_df\n",
    "\n",
    "def generate_business_insights(all_data):\n",
    "    \"\"\"Generate actionable business insights\"\"\"\n",
    "    \n",
    "    insights = {\n",
    "        'optimal_price_range': None,\n",
    "        'high_demand_products': [],\n",
    "        'seasonal_trends': {},\n",
    "        'competitor_gaps': [],\n",
    "        'market_opportunities': []\n",
    "    }\n",
    "    \n",
    "    # Analyze optimal pricing\n",
    "    price_demand_correlation = np.corrcoef(all_data['prices'], all_data['demand'])\n",
    "    \n",
    "    # Identify market gaps\n",
    "    # Analyze competitor offerings vs. market demand\n",
    "    \n",
    "    return insights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0eb790b",
   "metadata": {},
   "source": [
    "## Data Collection Automation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a969d692",
   "metadata": {},
   "outputs": [],
   "source": [
    "import schedule\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "class WoodworkingMarketResearch:\n",
    "    def __init__(self):\n",
    "        self.data_store = []\n",
    "    \n",
    "    def daily_data_collection(self):\n",
    "        \"\"\"Collect market data daily\"\"\"\n",
    "        \n",
    "        # Google Trends data\n",
    "        trends_data = analyze_woodworking_trends()\n",
    "        \n",
    "        # Local business data\n",
    "        local_data = analyze_local_woodworking_businesses(\"Your City, State\", \"API_KEY\")\n",
    "        \n",
    "        # E-commerce data\n",
    "        etsy_data = analyze_etsy_woodworking_market(\"ETSY_API_KEY\")\n",
    "        \n",
    "        # Combine and store data\n",
    "        daily_snapshot = {\n",
    "            'date': datetime.now(),\n",
    "            'trends': trends_data,\n",
    "            'local_businesses': local_data,\n",
    "            'ecommerce_data': etsy_data\n",
    "        }\n",
    "        \n",
    "        self.data_store.append(daily_snapshot)\n",
    "        \n",
    "        # Save to CSV\n",
    "        self.save_daily_report()\n",
    "    \n",
    "    def save_daily_report(self):\n",
    "        \"\"\"Save collected data to CSV\"\"\"\n",
    "        if self.data_store:\n",
    "            df = pd.DataFrame(self.data_store)\n",
    "            filename = f\"woodworking_market_data_{datetime.now().strftime('%Y%m%d')}.csv\"\n",
    "            df.to_csv(filename, index=False)\n",
    "            print(f\"Market data saved: {filename}\")\n",
    "\n",
    "# Schedule daily data collection\n",
    "researcher = WoodworkingMarketResearch()\n",
    "schedule.every().day.at(\"09:00\").do(researcher.daily_data_collection)\n",
    "\n",
    "# Run the scheduler\n",
    "while True:\n",
    "    schedule.run_pending()\n",
    "    time.sleep(3600)  # Check every hour"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184f17af",
   "metadata": {},
   "source": [
    "Marketing and Forecasting Research\n",
    "=====================================\n",
    "\n",
    "# Market Research Data Sources\n",
    "\n",
    "## Industry Reports & Analytics\n",
    "\n",
    "# Google Trends for woodworking demand\n",
    "from pytrends.request import TrendReq\n",
    "\n",
    "def analyze_woodworking_trends():\n",
    "    pytrends = TrendReq(hl='en-US', tz=360)\n",
    "    \n",
    "    # Woodworking-related keywords\n",
    "    keywords = ['custom furniture', 'woodworking', 'handmade furniture', \n",
    "               'live edge table', 'custom cabinets']\n",
    "    \n",
    "    pytrends.build_payload(keywords, timeframe='today 12-m', geo='US')\n",
    "    \n",
    "    # Get interest over time\n",
    "    trends_data = pytrends.interest_over_time()\n",
    "    \n",
    "    # Get related queries\n",
    "    related_queries = pytrends.related_queries()\n",
    "    \n",
    "    return trends_data, related_queries\n",
    "\n",
    "trends, queries = analyze_woodworking_trends()\n",
    "\n",
    "### Anthropic Attempted Fix\n",
    "\n",
    "import time\n",
    "import random\n",
    "from pytrends.request import TrendReq\n",
    "import pandas as pd\n",
    "\n",
    "def analyze_woodworking_trends():\n",
    "    try:\n",
    "        # Initialize with different settings\n",
    "        pytrends = TrendReq(hl='en-US', tz=360, timeout=(10,25), retries=2, backoff_factor=0.1)\n",
    "        \n",
    "        # Use fewer keywords (max 5 per request)\n",
    "        keywords = ['custom furniture', 'woodworking', 'handmade furniture']\n",
    "        \n",
    "        # Add random delay to avoid rate limiting\n",
    "        time.sleep(random.uniform(1, 3))\n",
    "        \n",
    "        print(\"Building payload...\")\n",
    "        pytrends.build_payload(keywords, timeframe='today 12-m', geo='US')\n",
    "        \n",
    "        print(\"Getting interest over time...\")\n",
    "        trends_data = pytrends.interest_over_time()\n",
    "        \n",
    "        # Add delay before next request\n",
    "        time.sleep(random.uniform(2, 4))\n",
    "        \n",
    "        print(\"Getting related queries...\")\n",
    "        related_queries = pytrends.related_queries()\n",
    "        \n",
    "        return trends_data, related_queries\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        print(\"Trying alternative approach...\")\n",
    "        return analyze_with_smaller_batches()\n",
    "\n",
    "def analyze_with_smaller_batches():\n",
    "    \"\"\"Alternative approach with individual keyword analysis\"\"\"\n",
    "    pytrends = TrendReq(hl='en-US', tz=360, timeout=(10,25), retries=2, backoff_factor=0.1)\n",
    "    \n",
    "    keywords = ['woodworking', 'custom furniture', 'handmade furniture']\n",
    "    all_data = {}\n",
    "    \n",
    "    for keyword in keywords:\n",
    "        try:\n",
    "            print(f\"Analyzing: {keyword}\")\n",
    "            time.sleep(random.uniform(2, 4))  # Longer delay between requests\n",
    "            \n",
    "            pytrends.build_payload([keyword], timeframe='today 12-m', geo='US')\n",
    "            trends = pytrends.interest_over_time()\n",
    "            \n",
    "            if not trends.empty:\n",
    "                all_data[keyword] = trends[keyword]\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Failed for {keyword}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    if all_data:\n",
    "        combined_df = pd.DataFrame(all_data)\n",
    "        return combined_df, None\n",
    "    else:\n",
    "        return None, None\n",
    "\n",
    "# Run the analysis\n",
    "print(\"Starting woodworking trends analysis...\")\n",
    "trends, queries = analyze_woodworking_trends()\n",
    "\n",
    "if trends is not None and not trends.empty:\n",
    "    print(\"\\n=== TRENDS DATA ===\")\n",
    "    print(trends.head())\n",
    "    print(f\"\\nShape: {trends.shape}\")\n",
    "    \n",
    "    if queries:\n",
    "        print(\"\\n=== RELATED QUERIES ===\")\n",
    "        for keyword, query_data in queries.items():\n",
    "            print(f\"\\n{keyword.upper()}:\")\n",
    "            if query_data['top'] is not None:\n",
    "                print(\"Top queries:\")\n",
    "                print(query_data['top'].head())\n",
    "else:\n",
    "    print(\"No data retrieved. Google Trends might be blocking requests.\")\n",
    "    print(\"Try again later or use a different approach.\")\n",
    "\n",
    "### Google Fix\n",
    "\n",
    "# Google Trends for woodworking demand\n",
    "import pandas as pd\n",
    "from pytrends.request import TrendReq\n",
    "import time # Import the time module to pause between requests\n",
    "\n",
    "def analyze_woodworking_trends():\n",
    "    \"\"\"\n",
    "    Analyzes Google Trends for woodworking keywords.\n",
    "\n",
    "    Fetches interest over time for a list of keywords and then fetches\n",
    "    related queries for each keyword individually.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing interest over time data.\n",
    "        dict: A dictionary containing related queries for each keyword.\n",
    "    \"\"\"\n",
    "    pytrends = TrendReq(hl='en-US', tz=360)\n",
    "    \n",
    "    # Woodworking-related keywords\n",
    "    keywords = ['custom furniture', 'woodworking', 'handmade furniture', \n",
    "               'live edge table', 'custom cabinets']\n",
    "    \n",
    "    # --- 1. Get Interest Over Time for all keywords (for comparison) ---\n",
    "    print(\"Fetching interest over time for all keywords...\")\n",
    "    pytrends.build_payload(keywords, timeframe='today 12-m', geo='US')\n",
    "    trends_data = pytrends.interest_over_time()\n",
    "    \n",
    "    # --- 2. Get Related Queries for each keyword individually ---\n",
    "    related_queries_dict = {}\n",
    "    print(\"\\nFetching related queries for each keyword...\")\n",
    "    \n",
    "    for keyword in keywords:\n",
    "        print(f\"Fetching for: '{keyword}'\")\n",
    "        # Build a new payload for each individual keyword\n",
    "        pytrends.build_payload([keyword], timeframe='today 12-m', geo='US')\n",
    "        \n",
    "        # Add a small delay to avoid making requests too quickly\n",
    "        time.sleep(1) \n",
    "        \n",
    "        try:\n",
    "            related_queries_dict[keyword] = pytrends.related_queries()\n",
    "        except Exception as e:\n",
    "            print(f\"Could not fetch related queries for '{keyword}'. Error: {e}\")\n",
    "            related_queries_dict[keyword] = None\n",
    "\n",
    "    return trends_data, related_queries_dict\n",
    "\n",
    "# Run the analysis\n",
    "trends_df, related_queries = analyze_woodworking_trends()\n",
    "\n",
    "# --- Display the results ---\n",
    "print(\"\\n--- Interest Over Time ---\")\n",
    "print(trends_df.tail()) # Print the last 5 rows of the trend data\n",
    "\n",
    "print(\"\\n\\n--- Related Queries ---\")\n",
    "for keyword, queries in related_queries.items():\n",
    "    if queries:\n",
    "        print(f\"\\nTop Related Queries for '{keyword}':\")\n",
    "        # The result is a dictionary where the value is another dictionary with 'top' and 'rising'\n",
    "        top_queries = queries[keyword]['top']\n",
    "        if top_queries is not None and not top_queries.empty:\n",
    "            print(top_queries)\n",
    "        else:\n",
    "            print(\"No top related queries found.\")\n",
    "\n",
    "#### Google Response to Broken API Endpoint\n",
    "\n",
    "     ```\n",
    "\n",
    "# Google Trends for woodworking demand\n",
    "\n",
    "from pytrends.request import TrendReq\n",
    "\n",
    "\n",
    "def analyze_woodworking_trends():\n",
    "\n",
    "pytrends = TrendReq(hl='en-US', tz=360)\n",
    "\n",
    "# Woodworking-related keywords\n",
    "\n",
    "keywords = ['custom furniture', 'woodworking', 'handmade furniture',\n",
    "\n",
    "'live edge table', 'custom cabinets']\n",
    "\n",
    "pytrends.build_payload(keywords, timeframe='today 12-m', geo='US')\n",
    "\n",
    "# Get interest over time\n",
    "\n",
    "trends_data = pytrends.interest_over_time()\n",
    "\n",
    "# Get related queries\n",
    "\n",
    "related_queries = pytrends.related_queries()\n",
    "\n",
    "return trends_data, related_queries\n",
    "\n",
    "\n",
    "trends, queries = analyze_woodworking_trends()\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "/home/lubuntu/myenv/lib/python3.12/site-packages/pytrends/request.py:260: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
    "\n",
    "df = df.fillna(False)\n",
    "\n",
    "\n",
    "---------------------------------------------------------------------------\n",
    "\n",
    "IndexError Traceback (most recent call last)\n",
    "\n",
    "Cell In[4], line 21\n",
    "\n",
    "17 related_queries = pytrends.related_queries()\n",
    "\n",
    "19 return trends_data, related_queries\n",
    "\n",
    "---> 21 trends, queries = analyze_woodworking_trends()\n",
    "\n",
    "Cell In[4], line 17, in analyze_woodworking_trends()\n",
    "\n",
    "14 trends_data = pytrends.interest_over_time()\n",
    "\n",
    "16 # Get related queries\n",
    "\n",
    "---> 17 related_queries = pytrends.related_queries()\n",
    "\n",
    "19 return trends_data, related_queries\n",
    "\n",
    "File ~/myenv/lib/python3.12/site-packages/pytrends/request.py:450, in TrendReq.related_queries(self)\n",
    "\n",
    "447 # top queries\n",
    "\n",
    "448 try:\n",
    "\n",
    "449 top_df = pd.DataFrame(\n",
    "\n",
    "--> 450 req_json['default']['rankedList'][0]['rankedKeyword'])\n",
    "\n",
    "451 top_df = top_df[['query', 'value']]\n",
    "\n",
    "452 except KeyError:\n",
    "\n",
    "453 # in case no top queries are found, the lines above will throw a KeyError\n",
    "\n",
    "IndexError: list index out of range\n",
    "\n",
    "Outline\n",
    "\n",
    "    Diagnosis of the IndexError: An explanation of why the IndexError: list index out of range occurs when using related_queries() with multiple keywords.\n",
    "\n",
    "    The Solution: A description of the correct approach, which involves iterating through each keyword to fetch its related queries individually.\n",
    "\n",
    "    Corrected Python Code: A complete, runnable code snippet that implements the solution and correctly fetches both interest over time for all keywords and related queries for each keyword.\n",
    "\n",
    "    Explanation of Changes: A step-by-step breakdown of the modifications made to the original code.\n",
    "\n",
    "    A Note on the FutureWarning: A brief explanation of the warning message appearing in the output.\n",
    "\n",
    "1. Diagnosis of the IndexError\n",
    "\n",
    "Hello! I can help you with this Python error. The IndexError: list index out of range you're encountering is a common issue when using the pytrends library.\n",
    "\n",
    "The root cause of the problem is that the pytrends.related_queries() method is designed to fetch data for only one keyword at a time.\n",
    "\n",
    "In your original code, you build a single payload with a list of five keywords:\n",
    "pytrends.build_payload(keywords, ...)\n",
    "\n",
    "While interest_over_time() can handle multiple keywords to generate a comparison chart, related_queries() cannot. When it receives a payload with more than one keyword, the Google Trends API returns a data structure that pytrends doesn't expect. Specifically, the list that should contain the related query data (rankedList) comes back empty. The library then tries to access the first element of this empty list ([0]), which triggers the IndexError.\n",
    "\n",
    "2. The Solution\n",
    "\n",
    "To fix this, you need to separate the logic for fetching \"interest over time\" and \"related queries.\"\n",
    "\n",
    "    Interest Over Time: You can continue to fetch this data in a single call with all your keywords to get a comparison.\n",
    "\n",
    "    Related Queries: You must loop through your list of keywords and make a separate API call for each one. You can store the results in a dictionary where the keys are your keywords and the values are the corresponding related queries.\n",
    "\n",
    "3. Corrected Python Code\n",
    "\n",
    "Here is the corrected and complete code. This version first gets the comparison data for all keywords and then iterates through each keyword to safely get its related queries.\n",
    "Python\n",
    "\n",
    "# Google Trends for woodworking demand\n",
    "import pandas as pd\n",
    "from pytrends.request import TrendReq\n",
    "import time # Import the time module to pause between requests\n",
    "\n",
    "def analyze_woodworking_trends():\n",
    "    \"\"\"\n",
    "    Analyzes Google Trends for woodworking keywords.\n",
    "\n",
    "    Fetches interest over time for a list of keywords and then fetches\n",
    "    related queries for each keyword individually.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing interest over time data.\n",
    "        dict: A dictionary containing related queries for each keyword.\n",
    "    \"\"\"\n",
    "    pytrends = TrendReq(hl='en-US', tz=360)\n",
    "    \n",
    "    # Woodworking-related keywords\n",
    "    keywords = ['custom furniture', 'woodworking', 'handmade furniture', \n",
    "               'live edge table', 'custom cabinets']\n",
    "    \n",
    "    # --- 1. Get Interest Over Time for all keywords (for comparison) ---\n",
    "    print(\"Fetching interest over time for all keywords...\")\n",
    "    pytrends.build_payload(keywords, timeframe='today 12-m', geo='US')\n",
    "    trends_data = pytrends.interest_over_time()\n",
    "    \n",
    "    # --- 2. Get Related Queries for each keyword individually ---\n",
    "    related_queries_dict = {}\n",
    "    print(\"\\nFetching related queries for each keyword...\")\n",
    "    \n",
    "    for keyword in keywords:\n",
    "        print(f\"Fetching for: '{keyword}'\")\n",
    "        # Build a new payload for each individual keyword\n",
    "        pytrends.build_payload([keyword], timeframe='today 12-m', geo='US')\n",
    "        \n",
    "        # Add a small delay to avoid making requests too quickly\n",
    "        time.sleep(1) \n",
    "        \n",
    "        try:\n",
    "            related_queries_dict[keyword] = pytrends.related_queries()\n",
    "        except Exception as e:\n",
    "            print(f\"Could not fetch related queries for '{keyword}'. Error: {e}\")\n",
    "            related_queries_dict[keyword] = None\n",
    "\n",
    "    return trends_data, related_queries_dict\n",
    "\n",
    "# Run the analysis\n",
    "trends_df, related_queries = analyze_woodworking_trends()\n",
    "\n",
    "# --- Display the results ---\n",
    "print(\"\\n--- Interest Over Time ---\")\n",
    "print(trends_df.tail()) # Print the last 5 rows of the trend data\n",
    "\n",
    "print(\"\\n\\n--- Related Queries ---\")\n",
    "for keyword, queries in related_queries.items():\n",
    "    if queries:\n",
    "        print(f\"\\nTop Related Queries for '{keyword}':\")\n",
    "        # The result is a dictionary where the value is another dictionary with 'top' and 'rising'\n",
    "        top_queries = queries[keyword]['top']\n",
    "        if top_queries is not None and not top_queries.empty:\n",
    "            print(top_queries)\n",
    "        else:\n",
    "            print(\"No top related queries found.\")\n",
    "\n",
    "4. Explanation of Changes\n",
    "\n",
    "    Separate API Calls: The core logic is now split. The call to get interest_over_time remains as it was, using the full list of keywords.\n",
    "\n",
    "    Loop for Related Queries: A for loop iterates through your keywords list.\n",
    "\n",
    "    Single-Keyword Payload: Inside the loop, pytrends.build_payload([keyword], ...) is called. Note that keyword is enclosed in square brackets [] because the method expects a list, even if it's just a list containing one item.\n",
    "\n",
    "    Storing Results: The results from pytrends.related_queries() are stored in a dictionary called related_queries_dict. This is a clean way to associate each keyword with its specific results.\n",
    "\n",
    "    Error Handling & Delay:\n",
    "\n",
    "        time.sleep(1): A one-second pause is added in the loop. It's good practice to add a small delay between API calls to avoid being rate-limited or blocked by Google for making too many requests too quickly.\n",
    "\n",
    "        try...except: I've wrapped the related_queries() call in a try...except block. This makes the code more robust. If Google Trends has no related query data for a specific term, it might still cause an error, and this block will catch it, print a message, and allow the script to continue to the next keyword instead of crashing.\n",
    "\n",
    "5. A Note on the FutureWarning\n",
    "\n",
    "You may still see this warning in your output:\n",
    "FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated...\n",
    "\n",
    "This warning is not causing your IndexError. It originates from the pandas library, which pytrends uses internally. It's simply informing you that a function pandas uses will behave differently in a future version. This is a message for the developers of pytrends to address in a future update. You can safely ignore this warning as it does not affect the execution or results of your code.\n",
    "\n",
    "\n",
    "Fetching related queries for each keyword...\n",
    "\n",
    "Fetching for: 'custom furniture'\n",
    "\n",
    "Could not fetch related queries for 'custom furniture'. Error: list index out of range\n",
    "\n",
    "Fetching for: 'woodworking'\n",
    "\n",
    "Could not fetch related queries for 'woodworking'. Error: list index out of range\n",
    "\n",
    "Fetching for: 'handmade furniture'\n",
    "\n",
    "Could not fetch related queries for 'handmade furniture'. Error: list index out of range\n",
    "\n",
    "Fetching for: 'live edge table'\n",
    "\n",
    "Could not fetch related queries for 'live edge table'. Error: list index out of range\n",
    "\n",
    "Fetching for: 'custom cabinets'\n",
    "\n",
    "Could not fetch related queries for 'custom cabinets'. Error: list index out of range\n",
    "\n",
    "\n",
    "--- Interest Over Time ---\n",
    "\n",
    "custom furniture woodworking handmade furniture \\\n",
    "\n",
    "date\n",
    "\n",
    "2025-06-01 10 70 1\n",
    "\n",
    "2025-06-08 12 68 1\n",
    "\n",
    "2025-06-15 10 71 1\n",
    "\n",
    "2025-06-22 10 73 1\n",
    "\n",
    "2025-06-29 11 66 1\n",
    "\n",
    "\n",
    "live edge table custom cabinets isPartial\n",
    "\n",
    "date\n",
    "\n",
    "2025-06-01 5 15 False\n",
    "\n",
    "2025-06-08 4 15 False\n",
    "\n",
    "2025-06-15 5 15 False\n",
    "\n",
    "2025-06-22 5 15 False\n",
    "\n",
    "2025-06-29 5 13 True\n",
    "\n",
    "\n",
    "\n",
    "--- Related Queries ---\n",
    "\n",
    "\n",
    "You've run into a frustrating and unfortunately common issue with the pytrends library. Your new output confirms that the error isn't just about sending multiple keywords at once, but is a more fundamental problem with the related_queries() function itself.\n",
    "\n",
    "Let's break down what's happening and how to build a more robust script to handle it.\n",
    "\n",
    "Outline\n",
    "\n",
    "    Diagnosis of the Persistent Error: An explanation of why the IndexError continues to happen even with single keywords, pointing to an issue within the pytrends library itself.\n",
    "\n",
    "    The Fragility of Unofficial Wrappers: A brief look at why libraries like pytrends can sometimes break.\n",
    "\n",
    "    Robust Solution: A revised code block that anticipates these errors and safely handles the data that is returned, preventing crashes and extracting whatever information is available.\n",
    "\n",
    "    Interpreting the New Results: How to understand the output from the robust script.\n",
    "\n",
    "1. Diagnosis of the Persistent Error\n",
    "\n",
    "The fact that you are now getting the IndexError: list index out of range for every single keyword tells us the problem lies within the pytrends library's ability to parse the response it's getting from Google.\n",
    "\n",
    "Here's the situation:\n",
    "\n",
    "    You send a valid request for a single keyword (e.g., 'woodworking').\n",
    "\n",
    "    Google Trends sends back a response.\n",
    "\n",
    "    The structure of this response has likely changed slightly from what the pytrends library was originally designed to expect.\n",
    "\n",
    "    When the related_queries() method tries to find the data in the specific location it's hard-coded to look (req_json['default']['rankedList'][0]), it finds an empty list ([]) and crashes when it tries to get the first item ([0]).\n",
    "\n",
    "This happens even when there are related queries visible on the Google Trends website. The issue is purely in the parsing step within the library.\n",
    "\n",
    "2. The Fragility of Unofficial Wrappers\n",
    "\n",
    "pytrends is an unofficial \"wrapper\" library. It works by mimicking a web browser to scrape the Google Trends website and access its internal API. This is a brilliant but fragile approach. If Google changes the backend structure of their website or API—even slightly—the library can break until its developers release a new version that accounts for the change. You appear to have caught it during one of these broken periods.\n",
    "\n",
    "3. Robust Solution\n",
    "\n",
    "We cannot fix the pytrends library itself, but we can write our Python code to be more defensive. The goal is to successfully call the function and then carefully inspect whatever data we get back, rather than assuming it's in the correct format.\n",
    "\n",
    "The code below is designed to handle this IndexError gracefully. It attempts the call and then safely checks the structure of the returned dictionary before trying to extract the 'top' and 'rising' queries.\n",
    "Python\n",
    "\n",
    "# Google Trends for woodworking demand\n",
    "import pandas as pd\n",
    "from pytrends.request import TrendReq\n",
    "import time\n",
    "\n",
    "def analyze_woodworking_trends():\n",
    "    \"\"\"\n",
    "    Analyzes Google Trends for woodworking keywords.\n",
    "\n",
    "    This robust version anticipates potential errors from the pytrends library\n",
    "    and handles them gracefully.\n",
    "    \"\"\"\n",
    "    pytrends = TrendReq(hl='en-US', tz=360)\n",
    "    \n",
    "    keywords = ['custom furniture', 'woodworking', 'handmade furniture', \n",
    "               'live edge table', 'custom cabinets']\n",
    "    \n",
    "    # --- 1. Get Interest Over Time (this part usually works reliably) ---\n",
    "    print(\"Fetching interest over time for all keywords...\")\n",
    "    try:\n",
    "        pytrends.build_payload(keywords, timeframe='today 12-m', geo='US')\n",
    "        trends_data = pytrends.interest_over_time()\n",
    "    except Exception as e:\n",
    "        print(f\"Could not fetch interest over time. Error: {e}\")\n",
    "        trends_data = None\n",
    "    \n",
    "    # --- 2. Get Related Queries with Robust Error Handling ---\n",
    "    related_queries_dict = {}\n",
    "    print(\"\\nFetching related queries for each keyword...\")\n",
    "    \n",
    "    for keyword in keywords:\n",
    "        print(f\"Fetching for: '{keyword}'\")\n",
    "        time.sleep(2) # Increased delay to be safe\n",
    "        \n",
    "        try:\n",
    "            # Re-build payload for each keyword\n",
    "            pytrends.build_payload([keyword], timeframe='today 12-m', geo='US')\n",
    "            related_queries_dict[keyword] = pytrends.related_queries()\n",
    "        except IndexError:\n",
    "            # This is the specific error we are seeing.\n",
    "            print(f\"  > Caught IndexError. Google's API response is not in the expected format for '{keyword}'.\")\n",
    "            related_queries_dict[keyword] = None # Mark as failed\n",
    "        except Exception as e:\n",
    "            # Catch any other potential errors\n",
    "            print(f\"  > An unexpected error occurred for '{keyword}': {e}\")\n",
    "            related_queries_dict[keyword] = None # Mark as failed\n",
    "            \n",
    "    return trends_data, related_queries_dict\n",
    "\n",
    "# --- Run the analysis and display results safely ---\n",
    "trends_df, related_queries = analyze_woodworking_trends()\n",
    "\n",
    "if trends_df is not None:\n",
    "    print(\"\\n\\n--- Interest Over Time ---\")\n",
    "    print(trends_df.tail())\n",
    "else:\n",
    "    print(\"\\n\\n--- No Interest Over Time data was fetched ---\")\n",
    "\n",
    "print(\"\\n\\n--- Related Queries ---\")\n",
    "if not related_queries:\n",
    "    print(\"No related queries could be fetched.\")\n",
    "else:\n",
    "    for keyword, result in related_queries.items():\n",
    "        print(f\"\\n--- Results for '{keyword}' ---\")\n",
    "        if result is None:\n",
    "            print(\"  > No data returned due to an API parsing error.\")\n",
    "            continue\n",
    "        \n",
    "        # Safely access 'top' and 'rising' queries\n",
    "        top_queries = result.get(keyword, {}).get('top')\n",
    "        rising_queries = result.get(keyword, {}).get('rising')\n",
    "        \n",
    "        if top_queries is not None and not top_queries.empty:\n",
    "            print(\"\\n  Top Related Queries:\")\n",
    "            print(top_queries)\n",
    "        else:\n",
    "            print(\"\\n  > No 'Top' related queries were found or could be parsed.\")\n",
    "            \n",
    "        if rising_queries is not None and not rising_queries.empty:\n",
    "            print(\"\\n  Rising Related Queries:\")\n",
    "            print(rising_queries)\n",
    "        else:\n",
    "            print(\"\\n  > No 'Rising' related queries were found or could be parsed.\")\n",
    "\n",
    "4. Interpreting the New Results\n",
    "\n",
    "When you run this new script, you will likely see a similar output to what you got before, but with more descriptive messages:\n",
    "Plaintext\n",
    "\n",
    "Fetching for: 'custom furniture'\n",
    "  > Caught IndexError. Google's API response is not in the expected format for 'custom furniture'.\n",
    "... (and so on for other keywords)\n",
    "\n",
    "At the end, the results section will clearly state that no data could be parsed.\n",
    "\n",
    "What to do now?\n",
    "\n",
    "    Wait for an Update: The most common solution is to wait for the pytrends developers to patch the library. You can check for updates periodically by running pip install --upgrade pytrends.\n",
    "\n",
    "    Try Different Parameters: You can experiment by changing the timeframe. Sometimes a shorter timeframe like 'today 3-m' or 'now 7-d' might use a different API endpoint that isn't broken.\n",
    "\n",
    "    Use the Website: For the time being, the most reliable way to get related queries is to go directly to the Google Trends website and search for your terms manually.\n",
    "\n",
    "\n",
    "\n",
    "## E-commerce Platform APIs\n",
    "\n",
    "# Google Trends for woodworking demand\n",
    "import pandas as pd\n",
    "from pytrends.request import TrendReq\n",
    "import time\n",
    "\n",
    "def analyze_woodworking_trends():\n",
    "    \"\"\"\n",
    "    Analyzes Google Trends for woodworking keywords.\n",
    "\n",
    "    This robust version anticipates potential errors from the pytrends library\n",
    "    and handles them gracefully.\n",
    "    \"\"\"\n",
    "    pytrends = TrendReq(hl='en-US', tz=360)\n",
    "    \n",
    "    keywords = ['custom furniture', 'woodworking', 'handmade furniture', \n",
    "               'live edge table', 'custom cabinets']\n",
    "    \n",
    "    # --- 1. Get Interest Over Time (this part usually works reliably) ---\n",
    "    print(\"Fetching interest over time for all keywords...\")\n",
    "    try:\n",
    "        pytrends.build_payload(keywords, timeframe='today 12-m', geo='US')\n",
    "        trends_data = pytrends.interest_over_time()\n",
    "    except Exception as e:\n",
    "        print(f\"Could not fetch interest over time. Error: {e}\")\n",
    "        trends_data = None\n",
    "    \n",
    "    # --- 2. Get Related Queries with Robust Error Handling ---\n",
    "    related_queries_dict = {}\n",
    "    print(\"\\nFetching related queries for each keyword...\")\n",
    "    \n",
    "    for keyword in keywords:\n",
    "        print(f\"Fetching for: '{keyword}'\")\n",
    "        time.sleep(2) # Increased delay to be safe\n",
    "        \n",
    "        try:\n",
    "            # Re-build payload for each keyword\n",
    "            pytrends.build_payload([keyword], timeframe='today 12-m', geo='US')\n",
    "            related_queries_dict[keyword] = pytrends.related_queries()\n",
    "        except IndexError:\n",
    "            # This is the specific error we are seeing.\n",
    "            print(f\"  > Caught IndexError. Google's API response is not in the expected format for '{keyword}'.\")\n",
    "            related_queries_dict[keyword] = None # Mark as failed\n",
    "        except Exception as e:\n",
    "            # Catch any other potential errors\n",
    "            print(f\"  > An unexpected error occurred for '{keyword}': {e}\")\n",
    "            related_queries_dict[keyword] = None # Mark as failed\n",
    "            \n",
    "    return trends_data, related_queries_dict\n",
    "\n",
    "# --- Run the analysis and display results safely ---\n",
    "trends_df, related_queries = analyze_woodworking_trends()\n",
    "\n",
    "if trends_df is not None:\n",
    "    print(\"\\n\\n--- Interest Over Time ---\")\n",
    "    print(trends_df.tail())\n",
    "else:\n",
    "    print(\"\\n\\n--- No Interest Over Time data was fetched ---\")\n",
    "\n",
    "print(\"\\n\\n--- Related Queries ---\")\n",
    "if not related_queries:\n",
    "    print(\"No related queries could be fetched.\")\n",
    "else:\n",
    "    for keyword, result in related_queries.items():\n",
    "        print(f\"\\n--- Results for '{keyword}' ---\")\n",
    "        if result is None:\n",
    "            print(\"  > No data returned due to an API parsing error.\")\n",
    "            continue\n",
    "        \n",
    "        # Safely access 'top' and 'rising' queries\n",
    "        top_queries = result.get(keyword, {}).get('top')\n",
    "        rising_queries = result.get(keyword, {}).get('rising')\n",
    "        \n",
    "        if top_queries is not None and not top_queries.empty:\n",
    "            print(\"\\n  Top Related Queries:\")\n",
    "            print(top_queries)\n",
    "        else:\n",
    "            print(\"\\n  > No 'Top' related queries were found or could be parsed.\")\n",
    "            \n",
    "        if rising_queries is not None and not rising_queries.empty:\n",
    "            print(\"\\n  Rising Related Queries:\")\n",
    "            print(rising_queries)\n",
    "        else:\n",
    "            print(\"\\n  > No 'Rising' related queries were found or could be parsed.\")\n",
    "\n",
    "# Etsy API for handmade/custom furniture market\n",
    "import requests\n",
    "\n",
    "def analyze_etsy_woodworking_market(api_key):\n",
    "    \"\"\"Analyze woodworking market on Etsy\"\"\"\n",
    "    \n",
    "    # Search for woodworking items\n",
    "    url = \"https://openapi.etsy.com/v3/application/listings/active\"\n",
    "    \n",
    "    headers = {\n",
    "        'x-api-key': api_key,\n",
    "        'Content-Type': 'application/json'\n",
    "    }\n",
    "    \n",
    "    params = {\n",
    "        'keywords': 'custom furniture woodworking',\n",
    "        'limit': 100,\n",
    "        'includes': 'Images,Shop,User',\n",
    "        'sort_on': 'score'\n",
    "    }\n",
    "    \n",
    "    response = requests.get(url, headers=headers, params=params)\n",
    "    listings = response.json()\n",
    "    \n",
    "    # Analyze pricing and demand indicators\n",
    "    market_data = []\n",
    "    for listing in listings.get('results', []):\n",
    "        market_data.append({\n",
    "            'title': listing.get('title'),\n",
    "            'price': listing.get('price', {}).get('amount'),\n",
    "            'currency': listing.get('price', {}).get('currency_code'),\n",
    "            'views': listing.get('views'),\n",
    "            'num_favorers': listing.get('num_favorers'),\n",
    "            'shop_name': listing.get('Shop', {}).get('shop_name'),\n",
    "            'creation_timestamp': listing.get('creation_timestamp')\n",
    "        })\n",
    "    \n",
    "    return market_data\n",
    "\n",
    "## Local Business Intelligence\n",
    "\n",
    "# Google My Business API for local competition analysis\n",
    "def analyze_local_woodworking_businesses(location, gmb_api_key):\n",
    "    \"\"\"Find local woodworking businesses and their performance\"\"\"\n",
    "    import googlemaps\n",
    "    \n",
    "    gmaps = googlemaps.Client(key=gmb_api_key)\n",
    "    \n",
    "    # Search for woodworking businesses\n",
    "    search_terms = [\n",
    "        'custom furniture',\n",
    "        'woodworking shop',\n",
    "        'cabinet maker',\n",
    "        'furniture maker'\n",
    "    ]\n",
    "    \n",
    "    local_businesses = []\n",
    "    \n",
    "    for term in search_terms:\n",
    "        places = gmaps.places_nearby(\n",
    "            location=location,\n",
    "            radius=50000,  # 50km radius\n",
    "            keyword=term,\n",
    "            type='establishment'\n",
    "        )\n",
    "        \n",
    "        for place in places.get('results', []):\n",
    "            place_details = gmaps.place(\n",
    "                place_id=place['place_id'],\n",
    "                fields=['name', 'rating', 'user_ratings_total', 'website', \n",
    "                       'formatted_phone_number', 'opening_hours', 'photos']\n",
    "            )\n",
    "            \n",
    "            local_businesses.append({\n",
    "                'name': place_details['result']['name'],\n",
    "                'rating': place_details['result'].get('rating'),\n",
    "                'review_count': place_details['result'].get('user_ratings_total'),\n",
    "                'website': place_details['result'].get('website'),\n",
    "                'search_term': term\n",
    "            })\n",
    "    \n",
    "    return local_businesses\n",
    "\n",
    "## Price Analysis Tools\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def analyze_pricing_data(market_data):\n",
    "    \"\"\"Analyze pricing patterns in woodworking market\"\"\"\n",
    "    \n",
    "    df = pd.DataFrame(market_data)\n",
    "    \n",
    "    # Price analysis by category\n",
    "    price_analysis = {\n",
    "        'avg_price': df['price'].mean(),\n",
    "        'median_price': df['price'].median(),\n",
    "        'price_range': {\n",
    "            'low': df['price'].quantile(0.25),\n",
    "            'high': df['price'].quantile(0.75)\n",
    "        },\n",
    "        'popular_price_points': df['price'].value_counts().head(10)\n",
    "    }\n",
    "    \n",
    "    # Demand indicators\n",
    "    demand_analysis = {\n",
    "        'avg_views': df['views'].mean(),\n",
    "        'avg_favorites': df['num_favorers'].mean(),\n",
    "        'high_demand_items': df.nlargest(10, 'views')[['title', 'price', 'views']]\n",
    "    }\n",
    "    \n",
    "    return price_analysis, demand_analysis\n",
    "\n",
    "def create_market_report(price_analysis, demand_analysis):\n",
    "    \"\"\"Generate market analysis report\"\"\"\n",
    "    \n",
    "    report = f\"\"\"\n",
    "    WOODWORKING MARKET ANALYSIS REPORT\n",
    "    ================================\n",
    "    \n",
    "    PRICING INSIGHTS:\n",
    "    - Average Price: ${price_analysis['avg_price']:.2f}\n",
    "    - Median Price: ${price_analysis['median_price']:.2f}\n",
    "    - Price Range (25th-75th percentile): ${price_analysis['price_range']['low']:.2f} - ${price_analysis['price_range']['high']:.2f}\n",
    "    \n",
    "    DEMAND INDICATORS:\n",
    "    - Average Views per Item: {demand_analysis['avg_views']:.0f}\n",
    "    - Average Favorites per Item: {demand_analysis['avg_favorites']:.0f}\n",
    "    \n",
    "    TOP PERFORMING ITEMS:\n",
    "    {demand_analysis['high_demand_items'].to_string()}\n",
    "    \"\"\"\n",
    "    \n",
    "    return report\n",
    "\n",
    "## Web Scraping for Public Business Directories\n",
    "\n",
    "# Scraping Yellow Pages or similar business directories (public data)\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "def scrape_business_directory(location, category=\"furniture\"):\n",
    "    \"\"\"Scrape public business directory data\"\"\"\n",
    "    \n",
    "    # This is for publicly available directory information\n",
    "    base_url = \"https://www.yellowpages.com/search\"\n",
    "    \n",
    "    params = {\n",
    "        'search_terms': f'{category} woodworking',\n",
    "        'geo_location_terms': location\n",
    "    }\n",
    "    \n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'\n",
    "    }\n",
    "    \n",
    "    businesses = []\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(base_url, params=params, headers=headers)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        \n",
    "        # Extract business information (adjust selectors based on site structure)\n",
    "        business_listings = soup.find_all('div', class_='result')\n",
    "        \n",
    "        for listing in business_listings:\n",
    "            name = listing.find('a', class_='business-name')\n",
    "            rating = listing.find('div', class_='rating')\n",
    "            \n",
    "            if name:\n",
    "                businesses.append({\n",
    "                    'name': name.get_text().strip(),\n",
    "                    'rating': rating.get_text().strip() if rating else 'N/A'\n",
    "                })\n",
    "        \n",
    "        time.sleep(2)  # Be respectful with requests\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error scraping directory: {e}\")\n",
    "    \n",
    "    return businesses\n",
    "\n",
    "## Social Media Market Research\n",
    "\n",
    "# Using official APIs for market research\n",
    "def analyze_woodworking_social_trends():\n",
    "    \"\"\"Analyze social media trends for woodworking\"\"\"\n",
    "    \n",
    "    # Instagram Hashtag Analysis (using official API)\n",
    "    woodworking_hashtags = [\n",
    "        '#customfurniture', '#woodworking', '#handmade', \n",
    "        '#liveedge', '#woodwork', '#furniture'\n",
    "    ]\n",
    "    \n",
    "    # YouTube Data API for woodworking content analysis\n",
    "    def get_youtube_woodworking_data(api_key):\n",
    "        from googleapiclient.discovery import build\n",
    "        \n",
    "        youtube = build('youtube', 'v3', developerKey=api_key)\n",
    "        \n",
    "        search_response = youtube.search().list(\n",
    "            q='woodworking business custom furniture',\n",
    "            part='id,snippet',\n",
    "            maxResults=50,\n",
    "            type='video',\n",
    "            order='relevance'\n",
    "        ).execute()\n",
    "        \n",
    "        video_data = []\n",
    "        for item in search_response['items']:\n",
    "            video_data.append({\n",
    "                'title': item['snippet']['title'],\n",
    "                'description': item['snippet']['description'],\n",
    "                'published_at': item['snippet']['publishedAt']\n",
    "            })\n",
    "        \n",
    "        return video_data\n",
    "    \n",
    "    return woodworking_hashtags\n",
    "\n",
    "## Demand Forecasting Model\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "\n",
    "def create_demand_forecast(historical_data):\n",
    "    \"\"\"Create demand forecast based on collected data\"\"\"\n",
    "    \n",
    "    df = pd.DataFrame(historical_data)\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df['month'] = df['date'].dt.month\n",
    "    df['year'] = df['date'].dt.year\n",
    "    \n",
    "    # Features for demand prediction\n",
    "    features = ['month', 'year', 'avg_price', 'search_volume']\n",
    "    X = df[features]\n",
    "    y = df['demand_indicator']  # Views, sales, etc.\n",
    "    \n",
    "    # Simple linear regression model\n",
    "    model = LinearRegression()\n",
    "    model.fit(X, y)\n",
    "    \n",
    "    # Forecast next 6 months\n",
    "    future_months = []\n",
    "    current_date = pd.Timestamp.now()\n",
    "    \n",
    "    for i in range(1, 7):\n",
    "        future_date = current_date + pd.DateOffset(months=i)\n",
    "        future_months.append({\n",
    "            'month': future_date.month,\n",
    "            'year': future_date.year,\n",
    "            'avg_price': df['avg_price'].mean(),  # Use historical average\n",
    "            'search_volume': df['search_volume'].mean()\n",
    "        })\n",
    "    \n",
    "    future_df = pd.DataFrame(future_months)\n",
    "    forecast = model.predict(future_df[features])\n",
    "    \n",
    "    return forecast, future_df\n",
    "\n",
    "def generate_business_insights(all_data):\n",
    "    \"\"\"Generate actionable business insights\"\"\"\n",
    "    \n",
    "    insights = {\n",
    "        'optimal_price_range': None,\n",
    "        'high_demand_products': [],\n",
    "        'seasonal_trends': {},\n",
    "        'competitor_gaps': [],\n",
    "        'market_opportunities': []\n",
    "    }\n",
    "    \n",
    "    # Analyze optimal pricing\n",
    "    price_demand_correlation = np.corrcoef(all_data['prices'], all_data['demand'])\n",
    "    \n",
    "    # Identify market gaps\n",
    "    # Analyze competitor offerings vs. market demand\n",
    "    \n",
    "    return insights\n",
    "\n",
    "## Data Collection Automation\n",
    "\n",
    "import schedule\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "class WoodworkingMarketResearch:\n",
    "    def __init__(self):\n",
    "        self.data_store = []\n",
    "    \n",
    "    def daily_data_collection(self):\n",
    "        \"\"\"Collect market data daily\"\"\"\n",
    "        \n",
    "        # Google Trends data\n",
    "        trends_data = analyze_woodworking_trends()\n",
    "        \n",
    "        # Local business data\n",
    "        local_data = analyze_local_woodworking_businesses(\"Your City, State\", \"API_KEY\")\n",
    "        \n",
    "        # E-commerce data\n",
    "        etsy_data = analyze_etsy_woodworking_market(\"ETSY_API_KEY\")\n",
    "        \n",
    "        # Combine and store data\n",
    "        daily_snapshot = {\n",
    "            'date': datetime.now(),\n",
    "            'trends': trends_data,\n",
    "            'local_businesses': local_data,\n",
    "            'ecommerce_data': etsy_data\n",
    "        }\n",
    "        \n",
    "        self.data_store.append(daily_snapshot)\n",
    "        \n",
    "        # Save to CSV\n",
    "        self.save_daily_report()\n",
    "    \n",
    "    def save_daily_report(self):\n",
    "        \"\"\"Save collected data to CSV\"\"\"\n",
    "        if self.data_store:\n",
    "            df = pd.DataFrame(self.data_store)\n",
    "            filename = f\"woodworking_market_data_{datetime.now().strftime('%Y%m%d')}.csv\"\n",
    "            df.to_csv(filename, index=False)\n",
    "            print(f\"Market data saved: {filename}\")\n",
    "\n",
    "# Schedule daily data collection\n",
    "researcher = WoodworkingMarketResearch()\n",
    "schedule.every().day.at(\"09:00\").do(researcher.daily_data_collection)\n",
    "\n",
    "# Run the scheduler\n",
    "while True:\n",
    "    schedule.run_pending()\n",
    "    time.sleep(3600)  # Check every hour\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
